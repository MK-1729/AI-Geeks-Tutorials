{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exploring Various color spaces \n",
    "#GRAYSCALE\n",
    "#HSV - Hue Saturation Value\n",
    "#LAB - Luminosity A(green-red) B(yellow-Blue)\n",
    "#threshold selection and canny edge detection alogrithm\n",
    "#drawing contours and counting them\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "image = cv2.imread(\"puppy.jpg\")\n",
    "cv2.namedWindow('Image', cv2.WINDOW_NORMAL)\n",
    "cv2.imshow(\"Image\", image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# convert the image to grayscale\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) \n",
    "cv2.namedWindow('Gray', cv2.WINDOW_NORMAL)\n",
    "cv2.imshow(\"Gray\", gray)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "\n",
    "#converting to HSV colorspace\n",
    "hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV) \n",
    "cv2.namedWindow('hsv', cv2.WINDOW_NORMAL)\n",
    "#display converted HSV image\n",
    "cv2.imshow(\"hsv\", hsv)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "#converting HSV image to Grayscale\n",
    "hsv_gray=cv2.cvtColor(hsv, cv2.COLOR_BGR2GRAY)\n",
    "cv2.namedWindow('hsv_gray', cv2.WINDOW_NORMAL)\n",
    "#display converted HSV gray image\n",
    "cv2.imshow('hsv_gray', hsv_gray)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting into high contrast image\n",
    "import cv2\n",
    "\n",
    "#-----Reading the image-----------------------------------------------------\n",
    "img = cv2.imread('puppy.jpg', 1)\n",
    "cv2.imshow(\"img\",img) \n",
    "cv2.waitKey(0)\n",
    "#-----Converting image to LAB Color model----------------------------------- \n",
    "lab= cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
    "cv2.imshow(\"lab\",lab)\n",
    "cv2.waitKey(0)\n",
    "#-----Splitting the LAB image to different channels-------------------------\n",
    "l, a, b = cv2.split(lab)\n",
    "cv2.imshow('l_channel', l)\n",
    "cv2.imshow('a_channel', a)\n",
    "cv2.imshow('b_channel', b)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "#-----Applying CLAHE to L-channel-------------------------------------------\n",
    "clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))\n",
    "cl = clahe.apply(l)\n",
    "cv2.imshow('CLAHE output', cl)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "#-----Merge the CLAHE enhanced L-channel with the a and b channel-----------\n",
    "limg = cv2.merge((cl,a,b))\n",
    "cv2.imshow('limg', limg)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "#-----Converting image from LAB Color model to RGB model--------------------\n",
    "high_contrast = cv2.cvtColor(limg, cv2.COLOR_LAB2BGR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"high_contrast\", high_contrast)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_gray = cv2.cvtColor(high_contrast, cv2.COLOR_BGR2GRAY) \n",
    "\n",
    "cv2.namedWindow('High Contrast Gray', cv2.WINDOW_NORMAL)\n",
    "cv2.imshow(\"High Contrast Gray\", high_gray)\n",
    "cv2.waitKey(0)\n",
    "#writing to file\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying gaussian blur on gray\n",
    "# apply a Gaussian blur with a 11x11 kernel to the image to smooth it,\n",
    "# useful when reducing high frequency noise\n",
    "blurred_gray = cv2.GaussianBlur(gray, (13,13), 0)\n",
    "cv2.imshow(\"Blurred Gray\", blurred_gray)\n",
    "\n",
    "H_blurred_gray = cv2.GaussianBlur(high_gray, (15,15), 0)\n",
    "cv2.imshow(\"High contrast Blurred Gray\", H_blurred_gray)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The Canny edge detector is an edge detection operator \n",
    "#that uses a multi-stage algorithm to detect a wide range of edges in images.\n",
    "#It was developed by John F. Canny in 1986. Canny also produced a computational theory of edge detection\n",
    "#explaining why the technique works. \n",
    "\n",
    "#Canny algorithm works best on gray scale. It takes four inputs:\n",
    "#Grayscale image\n",
    "#min threshold\n",
    "#max threshold\n",
    "#aperture size where default is 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "edged = cv2.Canny(gray, 40, 70, 3)\n",
    "cv2.namedWindow('Edged', cv2.WINDOW_NORMAL)\n",
    "cv2.imshow(\"Edged\", edged)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "edged = cv2.Canny(blurred_gray, 40, 70, 3)\n",
    "cv2.namedWindow('Edged', cv2.WINDOW_NORMAL)\n",
    "cv2.imshow(\"Edged\", edged)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "#threshold the image by setting all pixel values less than 225 to 255 (white; foreground) and all pixel values >= 170 to 255\n",
    "#(black; background), thereby segmenting the image\n",
    "thresh = cv2.threshold(blurred_gray, 70,255, cv2.THRESH_BINARY_INV)[1]\n",
    "cv2.namedWindow('Thresh', cv2.WINDOW_NORMAL)\n",
    "cv2.imshow(\"Thresh\", thresh)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find contours (i.e., outlines) of the foreground objects in the\n",
    "# thresholded image\n",
    "import imutils\n",
    "cnts = cv2.findContours(edged.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "cnts = imutils.grab_contours(cnts )\n",
    "output = image.copy()\n",
    " \n",
    "#loop over the contours\n",
    "for c in cnts:\n",
    "    # draw each contour on the output image with a 3px thick purple\n",
    "    # outline, then display the output contours one at a time\n",
    "    cv2.drawContours(output, [c], -1, (255, 0, 155), 3)\n",
    "    cv2.imshow(\"Contours\", output)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exercise 2\n",
    "#change gaussian blur and utilize the various color spaces if you can get the right number of cars in carpark image. \n",
    "#Think of using other threshold if possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# draw the total number of contours found in purple\n",
    "text = \"I found {} objects!\".format(len(cnts))\n",
    "cv2.putText(output, text, (10, 25),  cv2.FONT_HERSHEY_SIMPLEX, 0.7,(0, 240, 159), 2)\n",
    "cv2.imshow(\"Contours\", output)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
