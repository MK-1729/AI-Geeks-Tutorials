{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CustomDataset_Pytorch_googlenet",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1Y-92RHc1BunU357l9CrrA4JOpnem0QJL",
      "authorship_tag": "ABX9TyPLBgQG8O6eJoMA8QV+N9PV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MK-1729/AI-Geeks-Tutorials/blob/master/MK-1729/Training_Conv_Nets/CustomDatasets/CustomDataset_Pytorch_googlenet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bff2DHc7_Qlo"
      },
      "source": [
        "from os import listdir\r\n",
        "from os.path import isfile, join\r\n",
        "from os import walk\r\n",
        "import os \r\n",
        "import pandas as pd\r\n",
        "\r\n",
        "#onlyfiles = [f for f in listdir(mypath) if isfile(join(mypath, f))]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "kiSCuAdzim2J",
        "outputId": "836770de-8639-4b2f-8f12-011b75e4026d"
      },
      "source": [
        "# create dataframe\r\n",
        "df = pd.DataFrame(columns = ['img','label'])\r\n",
        "index=0\r\n",
        "root=\"/content/drive/MyDrive/Leaves_Dataset/D1/train\"\r\n",
        "for path, subdirs, files in os.walk(root):    \r\n",
        "    x=path.split('/')\r\n",
        "    if len(x)==7: continue\r\n",
        "    for name in files:\r\n",
        "        path_dir=os.path.join(x[7], name)\r\n",
        "        k=name.split(' ')\r\n",
        "        k=k[0].split('Class')\r\n",
        "        df.loc[index]=[path_dir,k[1]]\r\n",
        "        index=index+1\r\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>img</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Class (16)/R_0Class16 (3).jpg</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Class (16)/R_0Class16 (5).jpg</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Class (16)/R_0Class16 (1).jpg</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Class (16)/R_0Class16 (4).jpg</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Class (16)/R_0Class16 (2).jpg</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2283</th>\n",
              "      <td>Class (23)/R_270Class23 (6).jpg</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2284</th>\n",
              "      <td>Class (23)/R_270Class23 (76).jpg</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2285</th>\n",
              "      <td>Class (23)/R_270Class23 (9).jpg</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2286</th>\n",
              "      <td>Class (23)/R_315Class23 (12).jpg</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2287</th>\n",
              "      <td>Class (23)/R_315Class23 (33).jpg</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2288 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                   img label\n",
              "0        Class (16)/R_0Class16 (3).jpg    16\n",
              "1        Class (16)/R_0Class16 (5).jpg    16\n",
              "2        Class (16)/R_0Class16 (1).jpg    16\n",
              "3        Class (16)/R_0Class16 (4).jpg    16\n",
              "4        Class (16)/R_0Class16 (2).jpg    16\n",
              "...                                ...   ...\n",
              "2283   Class (23)/R_270Class23 (6).jpg    23\n",
              "2284  Class (23)/R_270Class23 (76).jpg    23\n",
              "2285   Class (23)/R_270Class23 (9).jpg    23\n",
              "2286  Class (23)/R_315Class23 (12).jpg    23\n",
              "2287  Class (23)/R_315Class23 (33).jpg    23\n",
              "\n",
              "[2288 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfBcm1mXo6HC"
      },
      "source": [
        "import torchvision.transforms as transforms\r\n",
        "from torch.utils.data import (\r\n",
        "    Dataset,\r\n",
        "    DataLoader,\r\n",
        ")  # Gives easier dataset managment and creates mini batches\r\n",
        "import torchvision.transforms as transforms \r\n",
        "from torch.utils.data import random_split\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torchvision\r\n",
        "import torch.optim as optim \r\n",
        "from skimage import io"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Hantg3-8Uyp"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\r\n",
        "\r\n",
        "# Hyperparameters\r\n",
        "in_channel = 3\r\n",
        "num_classes = 2\r\n",
        "learning_rate = 1e-3\r\n",
        "batch_size = 32\r\n",
        "num_epochs = 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0dRF3A0bMaws"
      },
      "source": [
        "class LeavesDataset(Dataset):\r\n",
        "    def __init__(self, csv_file, root_dir, transform=None):\r\n",
        "        self.annotations = csv_file\r\n",
        "        self.root_dir = root_dir\r\n",
        "        self.transform = transform\r\n",
        "\r\n",
        "    def __len__(self):\r\n",
        "        return len(self.annotations)\r\n",
        "\r\n",
        "    def __getitem__(self, index):\r\n",
        "        img_path = os.path.join(self.root_dir, self.annotations.iloc[index, 0])\r\n",
        "        image = io.imread(img_path)\r\n",
        "        y_label = torch.tensor(int(self.annotations.iloc[index, 1]))\r\n",
        "\r\n",
        "        if self.transform:\r\n",
        "            image = self.transform(image)\r\n",
        "\r\n",
        "        return (image, y_label)\r\n",
        "\r\n",
        "\r\n",
        "dataset = LeavesDataset(\r\n",
        "    csv_file=df,\r\n",
        "    root_dir=root,\r\n",
        "    transform=transforms.ToTensor(),\r\n",
        ")    \r\n",
        "batch_size=100\r\n",
        "train_set, test_set = random_split(dataset,[2000,288])\r\n",
        "train_loader = DataLoader(dataset=train_set, batch_size=batch_size, shuffle=True)\r\n",
        "test_loader = DataLoader(dataset=test_set, batch_size=batch_size, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JhWXdBuf636g",
        "outputId": "5338b265-9d1a-4668-a522-224014e064ad"
      },
      "source": [
        " # Model\r\n",
        "model = torchvision.models.googlenet(pretrained=True)\r\n",
        "model.to(device)\r\n",
        "\r\n",
        "# Loss and optimizer\r\n",
        "criterion = nn.CrossEntropyLoss()\r\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\r\n",
        "\r\n",
        "# Train Network\r\n",
        "for epoch in range(num_epochs):\r\n",
        "    losses = []\r\n",
        "\r\n",
        "    for batch_idx, (data, targets) in enumerate(train_loader):\r\n",
        "        # Get data to cuda if possible\r\n",
        "        data = data.to(device=device)\r\n",
        "        targets = targets.to(device=device)\r\n",
        "\r\n",
        "        # forward\r\n",
        "        scores = model(data)\r\n",
        "        loss = criterion(scores, targets)\r\n",
        "\r\n",
        "        losses.append(loss.item())\r\n",
        "\r\n",
        "        # backward\r\n",
        "        optimizer.zero_grad()\r\n",
        "        loss.backward()\r\n",
        "\r\n",
        "        # gradient descent or adam step\r\n",
        "        optimizer.step()\r\n",
        "\r\n",
        "    print(f\"Cost at epoch {epoch} is {sum(losses)/len(losses)}\")\r\n",
        "\r\n",
        "# Check accuracy on training to see how good our model is\r\n",
        "def check_accuracy(loader, model):\r\n",
        "    num_correct = 0\r\n",
        "    num_samples = 0\r\n",
        "    model.eval()\r\n",
        "\r\n",
        "    with torch.no_grad():\r\n",
        "        for x, y in loader:\r\n",
        "            x = x.to(device=device)\r\n",
        "            y = y.to(device=device)\r\n",
        "\r\n",
        "            scores = model(x)\r\n",
        "            _, predictions = scores.max(1)\r\n",
        "            num_correct += (predictions == y).sum()\r\n",
        "            num_samples += predictions.size(0)\r\n",
        "\r\n",
        "        print(\r\n",
        "            f\"Got {num_correct} / {num_samples} with accuracy {float(num_correct)/float(num_samples)*100:.2f}\"\r\n",
        "        )\r\n",
        "\r\n",
        "    model.train()\r\n",
        "\r\n",
        "\r\n",
        "print(\"Checking accuracy on Training Set\")\r\n",
        "check_accuracy(train_loader, model)\r\n",
        "\r\n",
        "print(\"Checking accuracy on Test Set\")\r\n",
        "check_accuracy(test_loader, model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cost at epoch 0 is 2.3314852595329283\n",
            "Cost at epoch 1 is 0.3565385572612286\n",
            "Cost at epoch 2 is 0.09452374819666147\n",
            "Cost at epoch 3 is 0.050683731539174916\n",
            "Cost at epoch 4 is 0.03422307022847235\n",
            "Cost at epoch 5 is 0.03661580216139555\n",
            "Cost at epoch 6 is 0.051416009990498425\n",
            "Cost at epoch 7 is 0.052148801693692806\n",
            "Cost at epoch 8 is 0.05490411017090082\n",
            "Cost at epoch 9 is 0.027390565164387225\n",
            "Checking accuracy on Training Set\n",
            "Got 1998 / 2000 with accuracy 99.90\n",
            "Checking accuracy on Test Set\n",
            "Got 277 / 288 with accuracy 96.18\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mk--E9r-8Kne"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}